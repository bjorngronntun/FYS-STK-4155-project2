{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will build models for classifications and test them on the credit card dataset. We begin by reading the data and splitting it into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "from src.models.logistic import *\n",
    "from src.preprocessing.preprocessing import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "path = '../data/raw/'\n",
    "\n",
    "X, y = get_design_matrix(path=path), get_target_values(path=path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simplest model\n",
    "Most clients do not default on their debt. In order to have a performance benchmark, we simply predict that no one defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7746666666666666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_predictions = np.zeros(y_test.shape)\n",
    "accuracy_score(y_test, naive_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "We will begin by trying out logistic regression from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try our own implementation of logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000\n",
      "Accuracy: 0.7635714285714286\n",
      "Epoch 2000\n",
      "Accuracy: 0.7830952380952381\n",
      "Epoch 3000\n",
      "Accuracy: 0.7978571428571428\n",
      "Epoch 4000\n",
      "Accuracy: 0.794047619047619\n",
      "Epoch 5000\n",
      "Accuracy: 0.7954761904761904\n",
      "Epoch 6000\n",
      "Accuracy: 0.7952380952380952\n",
      "Epoch 7000\n",
      "Accuracy: 0.7957142857142857\n",
      "Epoch 8000\n",
      "Accuracy: 0.794047619047619\n",
      "Epoch 9000\n",
      "Accuracy: 0.795952380952381\n",
      "Epoch 10000\n",
      "Accuracy: 0.7952380952380952\n",
      "Epoch 11000\n",
      "Accuracy: 0.795\n",
      "Epoch 12000\n",
      "Accuracy: 0.7992857142857143\n",
      "Epoch 13000\n",
      "Accuracy: 0.7947619047619048\n",
      "Epoch 14000\n",
      "Accuracy: 0.7952380952380952\n",
      "Epoch 15000\n",
      "Accuracy: 0.7954761904761904\n",
      "Epoch 16000\n",
      "Accuracy: 0.7961904761904762\n",
      "Epoch 17000\n",
      "Accuracy: 0.794047619047619\n",
      "Epoch 18000\n",
      "Accuracy: 0.7973809523809524\n",
      "Epoch 19000\n",
      "Accuracy: 0.7942857142857143\n",
      "Epoch 20000\n",
      "Accuracy: 0.7976190476190477\n",
      "Epoch 21000\n",
      "Accuracy: 0.7964285714285714\n",
      "Epoch 22000\n",
      "Accuracy: 0.7961904761904762\n",
      "Epoch 23000\n",
      "Accuracy: 0.8002380952380952\n",
      "Epoch 24000\n",
      "Accuracy: 0.7988095238095239\n",
      "Epoch 25000\n",
      "Accuracy: 0.8004761904761905\n",
      "Epoch 26000\n",
      "Accuracy: 0.7954761904761904\n",
      "Epoch 27000\n",
      "Accuracy: 0.7997619047619048\n",
      "Epoch 28000\n",
      "Accuracy: 0.7995238095238095\n",
      "Epoch 29000\n",
      "Accuracy: 0.7969047619047619\n",
      "Epoch 30000\n",
      "Accuracy: 0.7995238095238095\n",
      "Epoch 31000\n",
      "Accuracy: 0.7983333333333333\n",
      "Epoch 32000\n",
      "Accuracy: 0.7992857142857143\n",
      "Epoch 33000\n",
      "Accuracy: 0.7992857142857143\n",
      "Epoch 34000\n",
      "Accuracy: 0.8016666666666666\n",
      "Epoch 35000\n",
      "Accuracy: 0.7985714285714286\n",
      "Epoch 36000\n",
      "Accuracy: 0.800952380952381\n",
      "Epoch 37000\n",
      "Accuracy: 0.7992857142857143\n",
      "Epoch 38000\n",
      "Accuracy: 0.795952380952381\n",
      "Epoch 39000\n",
      "Accuracy: 0.7992857142857143\n",
      "Epoch 40000\n",
      "Accuracy: 0.7997619047619048\n",
      "Epoch 41000\n",
      "Accuracy: 0.7983333333333333\n",
      "Epoch 42000\n",
      "Accuracy: 0.8002380952380952\n",
      "Epoch 43000\n",
      "Accuracy: 0.8\n",
      "Epoch 44000\n",
      "Accuracy: 0.8007142857142857\n",
      "Epoch 45000\n",
      "Accuracy: 0.7995238095238095\n",
      "Epoch 46000\n",
      "Accuracy: 0.8035714285714286\n",
      "Epoch 47000\n",
      "Accuracy: 0.800952380952381\n",
      "Epoch 48000\n",
      "Accuracy: 0.8035714285714286\n",
      "Epoch 49000\n",
      "Accuracy: 0.8019047619047619\n",
      "Epoch 50000\n",
      "Accuracy: 0.7995238095238095\n",
      "Epoch 51000\n",
      "Accuracy: 0.8028571428571428\n",
      "Epoch 52000\n",
      "Accuracy: 0.8007142857142857\n",
      "Epoch 53000\n",
      "Accuracy: 0.8033333333333333\n",
      "Epoch 54000\n",
      "Accuracy: 0.8052380952380952\n",
      "Epoch 55000\n",
      "Accuracy: 0.8047619047619048\n",
      "Epoch 56000\n",
      "Accuracy: 0.804047619047619\n",
      "Epoch 57000\n",
      "Accuracy: 0.8052380952380952\n",
      "Epoch 58000\n",
      "Accuracy: 0.8023809523809524\n",
      "Epoch 59000\n",
      "Accuracy: 0.805\n",
      "Epoch 60000\n",
      "Accuracy: 0.8045238095238095\n",
      "Epoch 61000\n",
      "Accuracy: 0.7995238095238095\n",
      "Epoch 62000\n",
      "Accuracy: 0.8052380952380952\n",
      "Epoch 63000\n",
      "Accuracy: 0.8033333333333333\n",
      "Epoch 64000\n",
      "Accuracy: 0.8033333333333333\n",
      "Epoch 65000\n",
      "Accuracy: 0.8057142857142857\n",
      "Epoch 66000\n",
      "Accuracy: 0.805\n",
      "Epoch 67000\n",
      "Accuracy: 0.805952380952381\n",
      "Epoch 68000\n",
      "Accuracy: 0.805\n",
      "Epoch 69000\n",
      "Accuracy: 0.8047619047619048\n",
      "Epoch 70000\n",
      "Accuracy: 0.8078571428571428\n",
      "Epoch 71000\n",
      "Accuracy: 0.8035714285714286\n",
      "Epoch 72000\n",
      "Accuracy: 0.8057142857142857\n",
      "Epoch 73000\n",
      "Accuracy: 0.8073809523809524\n",
      "Epoch 74000\n",
      "Accuracy: 0.8071428571428572\n",
      "Epoch 75000\n",
      "Accuracy: 0.8073809523809524\n",
      "Epoch 76000\n",
      "Accuracy: 0.8030952380952381\n",
      "Epoch 77000\n",
      "Accuracy: 0.8007142857142857\n",
      "Epoch 78000\n",
      "Accuracy: 0.8080952380952381\n",
      "Epoch 79000\n",
      "Accuracy: 0.8028571428571428\n",
      "Epoch 80000\n",
      "Accuracy: 0.8076190476190476\n",
      "Epoch 81000\n",
      "Accuracy: 0.8045238095238095\n",
      "Epoch 82000\n",
      "Accuracy: 0.8045238095238095\n",
      "Epoch 83000\n",
      "Accuracy: 0.8083333333333333\n",
      "Epoch 84000\n",
      "Accuracy: 0.8073809523809524\n",
      "Epoch 85000\n",
      "Accuracy: 0.8061904761904762\n",
      "Epoch 86000\n",
      "Accuracy: 0.8071428571428572\n",
      "Epoch 87000\n",
      "Accuracy: 0.8104761904761905\n",
      "Epoch 88000\n",
      "Accuracy: 0.8085714285714286\n",
      "Epoch 89000\n",
      "Accuracy: 0.8054761904761905\n",
      "Epoch 90000\n",
      "Accuracy: 0.8088095238095238\n",
      "Epoch 91000\n",
      "Accuracy: 0.8080952380952381\n",
      "Epoch 92000\n",
      "Accuracy: 0.8042857142857143\n",
      "Epoch 93000\n",
      "Accuracy: 0.8035714285714286\n",
      "Epoch 94000\n",
      "Accuracy: 0.809047619047619\n",
      "Epoch 95000\n",
      "Accuracy: 0.8071428571428572\n",
      "Epoch 96000\n",
      "Accuracy: 0.805952380952381\n",
      "Epoch 97000\n",
      "Accuracy: 0.8057142857142857\n",
      "Epoch 98000\n",
      "Accuracy: 0.8066666666666666\n",
      "Epoch 99000\n",
      "Accuracy: 0.8092857142857143\n",
      "Epoch 100000\n",
      "Accuracy: 0.8071428571428572\n",
      "Epoch 101000\n",
      "Accuracy: 0.8123809523809524\n",
      "Epoch 102000\n",
      "Accuracy: 0.8083333333333333\n",
      "Epoch 103000\n",
      "Accuracy: 0.8064285714285714\n",
      "Epoch 104000\n",
      "Accuracy: 0.8133333333333334\n",
      "Epoch 105000\n",
      "Accuracy: 0.810952380952381\n",
      "Epoch 106000\n",
      "Accuracy: 0.8083333333333333\n",
      "Epoch 107000\n",
      "Accuracy: 0.8123809523809524\n",
      "Epoch 108000\n",
      "Accuracy: 0.81\n",
      "Epoch 109000\n",
      "Accuracy: 0.8107142857142857\n",
      "Epoch 110000\n",
      "Accuracy: 0.8073809523809524\n",
      "Epoch 111000\n",
      "Accuracy: 0.8123809523809524\n",
      "Epoch 112000\n",
      "Accuracy: 0.810952380952381\n",
      "Epoch 113000\n",
      "Accuracy: 0.8119047619047619\n",
      "Epoch 114000\n",
      "Accuracy: 0.8088095238095238\n",
      "Epoch 115000\n",
      "Accuracy: 0.8114285714285714\n",
      "Epoch 116000\n",
      "Accuracy: 0.8133333333333334\n",
      "Epoch 117000\n",
      "Accuracy: 0.8123809523809524\n",
      "Epoch 118000\n",
      "Accuracy: 0.8107142857142857\n",
      "Epoch 119000\n",
      "Accuracy: 0.8085714285714286\n",
      "Epoch 120000\n",
      "Accuracy: 0.809047619047619\n",
      "Epoch 121000\n",
      "Accuracy: 0.8107142857142857\n",
      "Epoch 122000\n",
      "Accuracy: 0.810952380952381\n",
      "Epoch 123000\n",
      "Accuracy: 0.8114285714285714\n",
      "Epoch 124000\n",
      "Accuracy: 0.8138095238095238\n",
      "Epoch 125000\n",
      "Accuracy: 0.81\n",
      "Epoch 126000\n",
      "Accuracy: 0.8083333333333333\n",
      "Epoch 127000\n",
      "Accuracy: 0.8130952380952381\n",
      "Epoch 128000\n",
      "Accuracy: 0.8126190476190476\n",
      "Epoch 129000\n",
      "Accuracy: 0.8123809523809524\n",
      "Epoch 130000\n",
      "Accuracy: 0.8135714285714286\n",
      "Epoch 131000\n",
      "Accuracy: 0.8123809523809524\n",
      "Epoch 132000\n",
      "Accuracy: 0.814047619047619\n",
      "Epoch 133000\n",
      "Accuracy: 0.8147619047619048\n",
      "Epoch 134000\n",
      "Accuracy: 0.8102380952380952\n",
      "Epoch 135000\n",
      "Accuracy: 0.8107142857142857\n",
      "Epoch 136000\n",
      "Accuracy: 0.8102380952380952\n",
      "Epoch 137000\n",
      "Accuracy: 0.8169047619047619\n",
      "Epoch 138000\n",
      "Accuracy: 0.8138095238095238\n",
      "Epoch 139000\n",
      "Accuracy: 0.8130952380952381\n",
      "Epoch 140000\n",
      "Accuracy: 0.8171428571428572\n",
      "Epoch 141000\n",
      "Accuracy: 0.8145238095238095\n",
      "Epoch 142000\n",
      "Accuracy: 0.8142857142857143\n",
      "Epoch 143000\n",
      "Accuracy: 0.8130952380952381\n",
      "Epoch 144000\n",
      "Accuracy: 0.810952380952381\n",
      "Epoch 145000\n",
      "Accuracy: 0.814047619047619\n",
      "Epoch 146000\n",
      "Accuracy: 0.8154761904761905\n",
      "Epoch 147000\n",
      "Accuracy: 0.8135714285714286\n",
      "Epoch 148000\n",
      "Accuracy: 0.815\n",
      "Epoch 149000\n",
      "Accuracy: 0.81\n",
      "Epoch 150000\n",
      "Accuracy: 0.8102380952380952\n",
      "Epoch 151000\n",
      "Accuracy: 0.8145238095238095\n",
      "Epoch 152000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 153000\n",
      "Accuracy: 0.8164285714285714\n",
      "Epoch 154000\n",
      "Accuracy: 0.8095238095238095\n",
      "Epoch 155000\n",
      "Accuracy: 0.8133333333333334\n",
      "Epoch 156000\n",
      "Accuracy: 0.8130952380952381\n",
      "Epoch 157000\n",
      "Accuracy: 0.8102380952380952\n",
      "Epoch 158000\n",
      "Accuracy: 0.81\n",
      "Epoch 159000\n",
      "Accuracy: 0.815\n",
      "Epoch 160000\n",
      "Accuracy: 0.8138095238095238\n",
      "Epoch 161000\n",
      "Accuracy: 0.8135714285714286\n",
      "Epoch 162000\n",
      "Accuracy: 0.8135714285714286\n",
      "Epoch 163000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 164000\n",
      "Accuracy: 0.8157142857142857\n",
      "Epoch 165000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 166000\n",
      "Accuracy: 0.8145238095238095\n",
      "Epoch 167000\n",
      "Accuracy: 0.8166666666666667\n",
      "Epoch 168000\n",
      "Accuracy: 0.8164285714285714\n",
      "Epoch 169000\n",
      "Accuracy: 0.8157142857142857\n",
      "Epoch 170000\n",
      "Accuracy: 0.8145238095238095\n",
      "Epoch 171000\n",
      "Accuracy: 0.8173809523809524\n",
      "Epoch 172000\n",
      "Accuracy: 0.8152380952380952\n",
      "Epoch 173000\n",
      "Accuracy: 0.8152380952380952\n",
      "Epoch 174000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 175000\n",
      "Accuracy: 0.8133333333333334\n",
      "Epoch 176000\n",
      "Accuracy: 0.8111904761904762\n",
      "Epoch 177000\n",
      "Accuracy: 0.8154761904761905\n",
      "Epoch 178000\n",
      "Accuracy: 0.8185714285714286\n",
      "Epoch 179000\n",
      "Accuracy: 0.814047619047619\n",
      "Epoch 180000\n",
      "Accuracy: 0.8157142857142857\n",
      "Epoch 181000\n",
      "Accuracy: 0.8130952380952381\n",
      "Epoch 182000\n",
      "Accuracy: 0.8130952380952381\n",
      "Epoch 183000\n",
      "Accuracy: 0.8192857142857143\n",
      "Epoch 184000\n",
      "Accuracy: 0.8157142857142857\n",
      "Epoch 185000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 186000\n",
      "Accuracy: 0.8169047619047619\n",
      "Epoch 187000\n",
      "Accuracy: 0.8176190476190476\n",
      "Epoch 188000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 189000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 190000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 191000\n",
      "Accuracy: 0.8171428571428572\n",
      "Epoch 192000\n",
      "Accuracy: 0.8164285714285714\n",
      "Epoch 193000\n",
      "Accuracy: 0.8169047619047619\n",
      "Epoch 194000\n",
      "Accuracy: 0.8180952380952381\n",
      "Epoch 195000\n",
      "Accuracy: 0.8169047619047619\n",
      "Epoch 196000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 197000\n",
      "Accuracy: 0.8166666666666667\n",
      "Epoch 198000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 199000\n",
      "Accuracy: 0.8135714285714286\n",
      "Epoch 200000\n",
      "Accuracy: 0.8178571428571428\n",
      "Epoch 201000\n",
      "Accuracy: 0.8147619047619048\n",
      "Epoch 202000\n",
      "Accuracy: 0.8173809523809524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203000\n",
      "Accuracy: 0.8173809523809524\n",
      "Epoch 204000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 205000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 206000\n",
      "Accuracy: 0.8169047619047619\n",
      "Epoch 207000\n",
      "Accuracy: 0.8166666666666667\n",
      "Epoch 208000\n",
      "Accuracy: 0.8171428571428572\n",
      "Epoch 209000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 210000\n",
      "Accuracy: 0.8147619047619048\n",
      "Epoch 211000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 212000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 213000\n",
      "Accuracy: 0.8173809523809524\n",
      "Epoch 214000\n",
      "Accuracy: 0.8176190476190476\n",
      "Epoch 215000\n",
      "Accuracy: 0.815952380952381\n",
      "Epoch 216000\n",
      "Accuracy: 0.8169047619047619\n",
      "Epoch 217000\n",
      "Accuracy: 0.8173809523809524\n",
      "Epoch 218000\n",
      "Accuracy: 0.815\n",
      "Epoch 219000\n",
      "Accuracy: 0.8173809523809524\n",
      "Epoch 220000\n",
      "Accuracy: 0.8178571428571428\n",
      "Epoch 221000\n",
      "Accuracy: 0.8161904761904762\n",
      "Epoch 222000\n",
      "Accuracy: 0.8183333333333334\n",
      "Epoch 223000\n",
      "Accuracy: 0.8176190476190476\n",
      "Test accuracy: 0.8132222222222222\n"
     ]
    }
   ],
   "source": [
    "lr = LogReg()\n",
    "lr.fit(X_train,\n",
    "       y_train,\n",
    "      iterations = 1000000,\n",
    "      lr = 0.01,\n",
    "      stochastic=True,\n",
    "      batch_size=128,\n",
    "      validation=True,\n",
    "      validation_size=0.2,\n",
    "      seed=12,\n",
    "      stopping_accuracy=0.82)\n",
    "predictions = lr.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, we obtain a test accuracy of 0.8132."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "Before trying our own implementation, we will use Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21000/21000 [==============================] - 1s 36us/step - loss: 0.4584 - accuracy: 0.8092\n",
      "Epoch 2/30\n",
      "21000/21000 [==============================] - 1s 26us/step - loss: 0.4321 - accuracy: 0.8229\n",
      "Epoch 3/30\n",
      "21000/21000 [==============================] - 1s 26us/step - loss: 0.4275 - accuracy: 0.8248\n",
      "Epoch 4/30\n",
      "21000/21000 [==============================] - 1s 26us/step - loss: 0.4250 - accuracy: 0.8261\n",
      "Epoch 5/30\n",
      "21000/21000 [==============================] - 1s 26us/step - loss: 0.4229 - accuracy: 0.8265\n",
      "Epoch 6/30\n",
      "21000/21000 [==============================] - 1s 26us/step - loss: 0.4209 - accuracy: 0.8280\n",
      "Epoch 7/30\n",
      "21000/21000 [==============================] - 1s 26us/step - loss: 0.4198 - accuracy: 0.8277\n",
      "Epoch 8/30\n",
      "21000/21000 [==============================] - 1s 30us/step - loss: 0.4182 - accuracy: 0.8280\n",
      "Epoch 9/30\n",
      "21000/21000 [==============================] - 1s 30us/step - loss: 0.4175 - accuracy: 0.8295\n",
      "Epoch 10/30\n",
      "21000/21000 [==============================] - 1s 29us/step - loss: 0.4162 - accuracy: 0.8295\n",
      "Epoch 11/30\n",
      "21000/21000 [==============================] - 1s 32us/step - loss: 0.4147 - accuracy: 0.8294\n",
      "Epoch 12/30\n",
      "21000/21000 [==============================] - 1s 33us/step - loss: 0.4140 - accuracy: 0.8307\n",
      "Epoch 13/30\n",
      "21000/21000 [==============================] - 1s 29us/step - loss: 0.4134 - accuracy: 0.8300\n",
      "Epoch 14/30\n",
      "21000/21000 [==============================] - 1s 31us/step - loss: 0.4126 - accuracy: 0.8307\n",
      "Epoch 15/30\n",
      "21000/21000 [==============================] - 1s 28us/step - loss: 0.4121 - accuracy: 0.8305\n",
      "Epoch 16/30\n",
      "21000/21000 [==============================] - 1s 33us/step - loss: 0.4112 - accuracy: 0.8306\n",
      "Epoch 17/30\n",
      "21000/21000 [==============================] - 1s 37us/step - loss: 0.4109 - accuracy: 0.8315\n",
      "Epoch 18/30\n",
      "21000/21000 [==============================] - 1s 31us/step - loss: 0.4099 - accuracy: 0.8317\n",
      "Epoch 19/30\n",
      "21000/21000 [==============================] - 1s 28us/step - loss: 0.4092 - accuracy: 0.8321\n",
      "Epoch 20/30\n",
      "21000/21000 [==============================] - 1s 37us/step - loss: 0.4083 - accuracy: 0.8320\n",
      "Epoch 21/30\n",
      "21000/21000 [==============================] - 1s 34us/step - loss: 0.4080 - accuracy: 0.8320\n",
      "Epoch 22/30\n",
      "21000/21000 [==============================] - 1s 37us/step - loss: 0.4071 - accuracy: 0.8323\n",
      "Epoch 23/30\n",
      "21000/21000 [==============================] - 1s 28us/step - loss: 0.4065 - accuracy: 0.8324\n",
      "Epoch 24/30\n",
      "21000/21000 [==============================] - 1s 27us/step - loss: 0.4059 - accuracy: 0.8321\n",
      "Epoch 25/30\n",
      "21000/21000 [==============================] - 1s 28us/step - loss: 0.4050 - accuracy: 0.8333\n",
      "Epoch 26/30\n",
      "21000/21000 [==============================] - 1s 27us/step - loss: 0.4045 - accuracy: 0.8340\n",
      "Epoch 27/30\n",
      "21000/21000 [==============================] - 1s 27us/step - loss: 0.4041 - accuracy: 0.8346\n",
      "Epoch 28/30\n",
      "21000/21000 [==============================] - 1s 27us/step - loss: 0.4029 - accuracy: 0.8337\n",
      "Epoch 29/30\n",
      "21000/21000 [==============================] - 1s 27us/step - loss: 0.4023 - accuracy: 0.8347\n",
      "Epoch 30/30\n",
      "21000/21000 [==============================] - 1s 28us/step - loss: 0.4016 - accuracy: 0.8357\n",
      "Test accuracy: 0.8118888888888889\n",
      "[0 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model, iterating on the data in batches of 64 samples\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=64)\n",
    "\n",
    "probabilities = model.predict(X_test)\n",
    "predictions = np.where(probabilities < 0.5, 0, 1).ravel()\n",
    "print('Test accuracy:', accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000\n",
      "Accuracy: 0.2361904761904762\n",
      "Epoch 2000\n",
      "Accuracy: 0.23047619047619047\n",
      "Stopped iterating, validation accuracy now is 0.8333333333333334\n",
      "Test accuracy: 0.814\n"
     ]
    }
   ],
   "source": [
    "from src.models.neural import *\n",
    "nn = NeuralNetwork(\n",
    "    layers = [\n",
    "        {\n",
    "            'neurons': 20,\n",
    "            'activation': 'tanh'\n",
    "        },\n",
    "        {\n",
    "            'neurons': 20,\n",
    "            'activation': 'tanh'\n",
    "        },\n",
    "        {\n",
    "            'neurons': 2,\n",
    "            'activation': 'softmax'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "nn.fit(X_train,\n",
    "       y_train,\n",
    "       iterations=500000,\n",
    "       batch_size=128,\n",
    "       learning_rate=0.1,\n",
    "       regularization=0.0091,\n",
    "       validation=True,\n",
    "       validation_size=0.05,\n",
    "       stopping_accuracy=0.83)\n",
    "predictions = nn.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
